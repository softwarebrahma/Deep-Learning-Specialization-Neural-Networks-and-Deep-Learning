
The general methodology to build a Neural Network is to:

1. Define the neural network structure ( # of input units,  # of hidden units, etc). 
2. Initialize the model's parameters.
3. Loop:
    - Implement forward propagation
    - Compute loss
    - Implement backward propagation to get the gradients
    - Update model parameters (gradient descent)

You often build helper functions to compute steps 1-3 and then merge them into one function we call nn_model().

Once you've built nn_model() and learnt the right parameters, you can make predictions on new data.

======

Interpretation:
The larger models (with more hidden units) are able to fit the training set better, until eventually the largest models overfit the data.
	- The best hidden layer size seems to be around n_h = 5. Indeed, a value around here seems to fits the data well without also incurring noticable overfitting.

You will also learn later about regularization, which lets you use very large models (such as n_h = 50) without much overfitting.

======


Reference:
http://scs.ryerson.ca/~aharley/neural-networks/
http://cs231n.github.io/neural-networks-case-study/


======

Linear regression, Bias & Variance decomposition of linear regression error.

Geoff Hinton's Deep Belief Net paper (Deep Belief Networks (DBN))
	- http://www.deeplearning.net/tutorial/DBN.html
	- http://www.cs.toronto.edu/~fritz/absps/ncfast.pdf
	- Deep Belief Networks with Boltzmann machines as builing blocks (10 years ago). Over time we switched to RELU, batch normalization, etc & deep learning became reliable.

Deep Learning why?
	- SVMs don't have the right asymptotics, add more training data & they slower. or for the same amount of training data its hard to make them perform a lot better by changing other settings.
	
GAN (Generative Adversarial Network)
	- https://arxiv.org/abs/1406.2661
	- https://en.wikipedia.org/wiki/Generative_adversarial_network
	- Way of generative modeling where you have a lot of training data & you'd like to learn to produce more examples that resemble the training data (that are artificial).
		- Better than Boltzmann machines & Sparse coding
	- Used for semi-supervised learning, generate training data for other models, simulating scientific experiments.
	- Right now not as reliable/stable.
	
MIT Deep Learning Book
	- Ian Goodfellow, Yoshua Bengio and Aaron Courville.
	- https://github.com/janishar/mit-deep-learning-book-pdf
	

Linear Algebra & Probability are VERY IMPORTANT to machine learning & deep learning.

History
	- We used algos to recognize patters in hand extracted features (humans creating the features), use cases like ad clicking predictions, scientific analysis, etc.
	- Millions of pixels in image, raw audio wake form where learning from scratch has to be done.
	- Paths forward, reinforcement learning work as well as supervised learning, unsupervised learning work as well as supervised learning, machine learning algos are fair & don't reflect biases that we prefer to avoid, AI benefiting everyone, etc.
	
Read book, practice the materials, post on GitHub & maybe on Archive.

Adversarial Examples
	- Beginning of a new field called Machine Learning Security
	- Fooling computers to run wrong code is application level security, fooling computers to believe messages on a n/w come from somebody that is not actually who they say they are is n/w level security.
	- Similarly fooling machine learning algos into doing things they shouldn't even if the program running the algo is running the correct code even if the program knows who all the messages in the n/w really came from.
	- Build it in, rather than add later.
	

	
