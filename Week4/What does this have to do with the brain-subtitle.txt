so what a deep learning have to do the brain at the risk of giving away the punchline I would say not a whole lot but let's take a quick look at why people keep making the analogy between deep learning and the human brain when you implement a neural network this is what you do for prop and back prop and I think because it's been difficult to convey intuitions about what these equations are doing really great and descends on a very complex function the analogy that is like the brain has become really an oversimplified explanation for what this is doing but the simplicity of this makes it you know kind of seductive for people to just say it publicly as well as the media to report it and certainly called the popular imagination and there is a very loose analogy between let's say a logistic regression unit with a sigmoid activation function and here's a cartoon of a single neuron in the brain in this picture of a biological neuron on this neuron which is a cell in your brain receives electric signals from you know other neurons mu X 1 X 2 X 3 or maybe from other neurons a 1 a 2 a 3 there's a simple thresholded computation and then if this neuron fires it sends a pulse of electricity down the axon down this long wire perhaps to other neurons so there is a very simplistic analogy between a single logistic unit between a single neuron and network and a biological neuron like that shown on a right but I think that today even neuroscientists have almost no idea what even a single neuron is doing a single neuron appears to be much more complex than we are able to characterize with neuroscience and while some of what is doing is a little bit like logistic regression there's still a lot about what even a single neuron does that no one there no human today understands for example exactly how neurons in the human brain learn this is still a very mysterious process and it's completely unclear today whether the human brain uses an algorithm does anything like back propagation or gradient descent or if there's some fundamentally different learning principle that the human brain uses so when I think of deep learning I think of it as being very good and learning very flexible functions very complex functions to learn X to Y mappings to learn input-output mappings in supervised learning and whereas D is like the brain analogy maybe that was useful once I think the field has moved to the point where that analogy is breaking down and I tend not to use that analogy much anymore so that's it so neural networks and their brain I do think that maybe the field of computer vision has taken a bit more inspiration from the human brains and other disciplines that also apply to learning but I personally use the analogy you know to the human brain less than I used to so that's it for this video you now know how to implement for prop and back prop in gradient descent even for deep neural networks best of luck with the pro exercise and I look forward to sharing more of these ideas of you in the second course